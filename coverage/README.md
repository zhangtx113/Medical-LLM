### 🧩 项目简介
该项目基于 **BERTScore** 与 **SpaCy 语义解析**，用于评估医学或教材类问答数据对原始文本的语义覆盖度。
此版本（全局提取版）直接从全文抽取语义短语（名词短语、动词短语）作为核心单元，不依赖问答内容锚定。


---


### 🚀 使用方法
1. **安装依赖**
```bash
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```


2. **运行示例**
```bash
python coverage_calculator.py
```
输出示例：
```
=== BSR 覆盖度计算（全局提取版） ===
原始文本：The heart muscle contracts rhythmically...
问答对数量：2
--------------------------------------------------
qna_1: 0.893 -> 高覆盖：问答对完全覆盖原始文本核心语义。
qna_2: 0.811 -> 中覆盖：覆盖大部分核心语义，仍有遗漏。


联合覆盖度: 0.874 -> 高覆盖
```


3. **自定义数据**
修改文件末尾：
```python
RAW_TEXT = "你的教材原文..."
QNA_PAIRS = [("问题1", "答案1"), ("问题2", "答案2")]
```


---


### 📈 输出指标
| 指标 | 含义 | 说明 |
|------|------|------|
| `individual_coverages` | 单个问答对覆盖度 | 衡量该问答对与原文语义单元的匹配程度 |
| `joint_coverage` | 联合覆盖度 | 衡量所有问答对对原文核心语义的总体覆盖 |


---


### 🧩 适用场景
- 教材知识点覆盖分析
- 医学知识问答生成评估
- 大模型SFT或RL数据质量验证


---


### 🧭 未来可扩展方向
- 🔹 中文版本（替换为 `zh_core_web_sm` + 中文BERT模型）
- 🔹 GPU加速嵌入生成（基于 `torch.cuda`）
- 🔹 核心短语筛选规则优化（引入TF-IDF或聚类）
- 🔹 批量评估脚本（支持数千问答对的覆盖统计）
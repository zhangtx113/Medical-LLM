#!/bin/bash
#SBATCH -J LoRA_Train_Model                         # ä½œä¸šå
#SBATCH --nodes=1
#SBATCH --gres=gpu:8                           # ä½¿ç”¨ 8 å¼  GPU
#SBATCH --cpus-per-task=48                     # åˆ†é… 48 ä¸ª CPU æ ¸å¿ƒ
#SBATCH --output=logs/LoRA_%j.out       # æ ‡å‡†è¾“å‡ºæ—¥å¿—
#SBATCH --error=logs/LoRA_%j.err        # é”™è¯¯è¾“å‡ºæ—¥å¿—

echo "ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹..."

# === åŠ è½½ç¯å¢ƒ ===
source /mnt/inaisfs/data/home/zhaozc_criait/miniconda3/etc/profile.d/conda.sh
conda activate medical-llm

# === è®¾ç½® SwanLab API Key ===
export SWANLAB_API_KEY="zZt33jJxQnffzLZB18XvZ"

# === åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½• ===
cd /mnt/inaisfs/data/home/zhaozc_criait/zhangtx/Medical_LLM/sft

# === è¿è¡Œè®­ç»ƒè„šæœ¬ ===
python train_lora.py

echo "âœ… æ¨¡å‹è®­ç»ƒä»»åŠ¡å®Œæˆ"
